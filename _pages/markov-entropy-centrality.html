---
title: Markov entropy centrality
permalink: /markov-entropy-centrality/
search: true
---

<html>
 <head>
  <meta charset="utf-8"/>
  <title>
   Markov entropy centrality
  </title>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6">
  </script>
  <script async="" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <style>
   body { font-family: Georgia, serif; margin: 36px; line-height: 1.6; }
    .references { margin-top: 1.2em; }
    .ref-item { margin-bottom: 0.5em; }
    .ref-num { display:inline-block; width:3em; font-weight:bold; color:#333; }
    ul { margin-left: 1.2em; }
  </style>
 </head>
 <body>
  <h2>
   Markov entropy centrality
  </h2>
  <p>
   <br/>
   <i>
    Markov entropy centrality
   </i>
   , originally called entropy centrality, is an entropy-based node centrality metric derived from a discrete random Markovian transfer process [2]. In this model, an object is transferred from a given node according to the following rules: at each step, the object is either absorbed by the current node with probability \(a\), terminating the process, or passed to one of its neighbors with probability \(1-a\), allowing the process to continue.
   <br/>
   The centrality of node \(i\), \(c_{\mathrm{MEC}}(i)\), is quantified by the entropy of the distribution of destinations reached by the object originating from \(i\) after \(t\) transitions:
   <br/>
   \[
   <br/>
   c_{\mathrm{MEC}}(i) = - \sum_{j=1}^N \left(p_{ij}^t + p_{ij'}^t\right) \log \left(p_{ij}^t + p_{ij'}^t\right),
   <br/>
   \]
   <br/>
   where \((p_{ij}^t + p_{ij'}^t)\) denotes the probability that the object, starting at node \(i\), is held by node \(j\) after \(t\) steps. The original \(2N \times 2N\) transition probability matrix \(P\) is defined as
   <br/>
   \[
   <br/>
   p_{ij} =
   <br/>
   \begin{cases}
   <br/>
   a, &amp; \text{if } j = i',\\
   <br/>
   1, &amp; \text{if } i = j = i',\\
   <br/>
   \frac{(1-a) a_{ij}}{d_i}, &amp; \text{otherwise,}
   <br/>
   \end{cases}
   <br/>
   \]
   <br/>
   where \(i'\) denotes the absorbing state corresponding to node \(i\), \(a_{ij}\) is the adjacency matrix entry, and \(d_i\) is the degree of node \(i\).
   <br/>
   By design, Markov entropy centrality measures a node's potential for information spread: nodes with high entropy can reach a diverse set of destinations with relatively even probability, indicating a structurally influential and versatile role. Conversely, low entropy implies that walks starting from the node are concentrated on a few targets, reflecting lower reach. Experimentally, Nikolaev et al. [2] suggest using \(t=5\) and absorption probability \(a \in [0.1, 0.2]\).
   <br/>
  </p>
  <h3>
   References
  </h3>
  <div class="references">
   <div class="ref-item">
    <span class="ref-num">
     [1]
    </span>
    Shvydun, S. (2025). Zoo of Centralities: Encyclopedia of Node Metrics in Complex Networks. arXiv: 2511.05122
    <a href="https://doi.org/10.48550/arXiv.2511.05122">
     https://doi.org/10.48550/arXiv.2511.05122
    </a>
   </div>
   <div class="ref-item">
    <span class="ref-num">
     [2]
    </span>
    Nikolaev, A. G., Razib, R., &amp; Kucheriya, A. (2015). On efficient use of entropy centrality for social network analysis and community detection. Social Networks, 40, 154-162.
    <a href="https://doi.org/10.1016/j.socnet.2014.10.002">
     doi: 10.1016/j.socnet.2014.10.002.
    </a>
   </div>
  </div>
  <hr style="margin-top: 2em; border: none; border-top: 1px solid #ddd;"/>
  <p style="text-align: right; font-size: 0.9em; color: #555;">
   Notice an issue on this page?
   <a href="https://forms.gle/5v2gEZE6ibaQupBv6" style="color: #004499;" target="_blank">
    Report it here.
   </a>
  </p>
 </body>
</html>
